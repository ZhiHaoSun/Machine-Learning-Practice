{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework #1 - The Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(This skeleton file is provided for HW#1 only.  You are expected to modify it for use in this and other homeworks for the course.)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the README section for A0000000X's submission.\n",
    "(For group submissions [when applicable], simply concatenate the student matric numbers in lexicographical order separated by a '-' (dash); e.g., A0000000X-A0000001Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Notes about this assignment \n",
    "\n",
    "Place your comments or requests here for the CS3244 staff to read.  Discuss your architecture or experiments in general.  A paragraph or two is usually sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files included with this submission\n",
    "\n",
    "List the files in your submission here and provide a short 1 line description of each file.  Make sure your submission's files are named and formatted correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Exercise 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import *  \n",
    "import numpy.random as nr\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time  \n",
    "# Plotting with style! \n",
    "import seaborn as sb \n",
    "\n",
    "# Size the plot appropriately for online display\n",
    "plt.rcParams['figure.figsize'] = (12.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fix the random number generator first, in case we need results that are replicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nr.seed(3244)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1: load data...\n",
      "step 2: training...\n",
      "Error of input is: [[ 0.55564664]]\n",
      "\n",
      "[[-0.67861174 -0.91886456  1.31188782 -1.62156996  0.19618585 -1.49043856\n",
      "  -0.0813952   1.89044304 -1.09839404  0.63017345  2.13711557  0.44252764\n",
      "  -1.43972683 -0.95257355  1.30120275  1.73754254  1.94029756 -1.88386902\n",
      "   2.03535238 -0.90499649 -1.54060159]]\n",
      "step 3: testing...\n",
      "Error of output is: [[ 0.58427082]]\n",
      "\n",
      "step 4: show the result...\n",
      "The classify accuracy is: 81.433%\n"
     ]
    }
   ],
   "source": [
    "#    Write your solution to the programming assignment here.  We've suggested some cells that you can add \n",
    "#    to your notebook as single line comments below.\n",
    "#    Please place all of your cells to be run in a linear, unintervened order, such that we can automate\n",
    "#    the running and grading of the assignment.\n",
    "\n",
    "# load datasets code\n",
    "# calculate the sigmoid function  \n",
    "# calculate the sigmoid function  \n",
    "def sigmoid(inX):  \n",
    "    return 1.0 / (1 + exp(-inX))  \n",
    "  # \n",
    "def loadData(path):  \n",
    "    train_x = []  \n",
    "    train_y = []  \n",
    "    fileIn = open(path)  \n",
    "    for line in fileIn.readlines():  \n",
    "        lineArr = line.strip().split()  \n",
    "\n",
    "        data = [1.0]\n",
    "\n",
    "        for i in range(0,20):\n",
    "        # for i in range(1,3):\n",
    "            data.append(float(lineArr[i]))\n",
    "\n",
    "        y = int(lineArr[20])\n",
    "\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "\n",
    "        train_x.append(data)  \n",
    "        train_y.append(y) \n",
    "\n",
    "    # print train_y \n",
    "    return mat(train_x), mat(train_y).transpose()  \n",
    "  \n",
    "# train a logistic regression model using some optional optimize algorithm  \n",
    "# input: train_x is a mat datatype, each row stands for one sample  \n",
    "#        train_y is mat datatype too, each row is the corresponding label  \n",
    "#        opts is optimize option include step and maximum number of iterations  \n",
    "def trainLogRegres(train_x, train_y, opts):  \n",
    "    # calculate training time  \n",
    "    startTime = time.time()  \n",
    "  \n",
    "    numSamples, numFeatures = shape(train_x)  \n",
    "    alpha = opts['alpha']; maxIter = opts['maxIter']  \n",
    "    weights = ones((numFeatures, 1))  \n",
    "\n",
    "    # optimize through gradient descent algorilthm  \n",
    "    for k in range(maxIter):  \n",
    "        if opts['optimizeType'] == 'gradDescent': # deterministic gradient descent algorilthm  \n",
    "            output = sigmoid(train_x * weights)  \n",
    "            error = train_y - output  \n",
    "            weights = weights + alpha * train_x.transpose() * error  \n",
    "        elif opts['optimizeType'] == 'stocGradDescent': # stochastic gradient descent  \n",
    "            for i in range(numSamples):  \n",
    "                output = sigmoid(train_x[i, :] * weights)  # pick some of the data\n",
    "                error = train_y[i, 0] - output  # only considers the error\n",
    "                weights = weights + alpha * train_x[i, :].transpose() * error  \n",
    "        else:  \n",
    "            raise NameError('Not support optimize method type!')  \n",
    "    \n",
    "    ein = 0\n",
    "    \n",
    "    for i in range(numSamples):\n",
    "        ein += np.log(1 + exp(- train_x[i, :] * weights * train_y[i , 0]))\n",
    "    \n",
    "    ein = ein / numSamples\n",
    "    \n",
    "    print('Error of input is: ' + str(ein) + '\\n')\n",
    "    \n",
    "    return weights  \n",
    "  \n",
    "  \n",
    "# test your trained Logistic Regression model given test set  \n",
    "def testLogRegres(weights, test_x, test_y):  \n",
    "    numSamples, numFeatures = shape(test_x)  \n",
    "    matchCount = 0  \n",
    "    \n",
    "    eout = 0\n",
    "    \n",
    "    for i in range(numSamples):  \n",
    "        result = (sigmoid(test_x[i, :] * weights)[0, 0])\n",
    "        eout += np.log(1 + exp(- test_x[i, :] * weights * test_y[i , 0]))\n",
    "        predict = result > 0.5\n",
    "\n",
    "        if predict == (int(test_y[i, 0]) > 0):  \n",
    "            matchCount += 1  \n",
    "        #     print str(i) + 'th success: ' + str(result) + '\\n'\n",
    "        # else:\n",
    "        #     print str(i) + 'th fails: ' + str(result) + '\\n'\n",
    "        \n",
    "    accuracy = float(matchCount) / numSamples  \n",
    "    eout = eout / numSamples\n",
    "    \n",
    "    print('Error of output is: ' + str(eout) + '\\n')\n",
    "    \n",
    "    return accuracy  \n",
    "\n",
    "# show your trained logistic regression model only available with 2-D data  \n",
    "def showLogRegres(weights, train_x, train_y):  \n",
    "    # notice: train_x and train_y is mat datatype  \n",
    "    numSamples, numFeatures = shape(train_x)  \n",
    "    if numFeatures != 3:  \n",
    "        print(\"Sorry! I can not draw because the dimension of your data is not 2!\")  \n",
    "        return 1  \n",
    "  \n",
    "    # draw all samples  \n",
    "    for i in range(numSamples):  \n",
    "        if int(train_y[i, 0]) == 0:  \n",
    "            plt.plot(train_x[i, 1], train_x[i, 2], 'or')  \n",
    "        elif int(train_y[i, 0]) == 1:  \n",
    "            plt.plot(train_x[i, 1], train_x[i, 2], 'ob')  \n",
    "  \n",
    "    # draw the classify line  \n",
    "    min_x = min(train_x[:, 1])[0, 0]  \n",
    "    max_x = max(train_x[:, 1])[0, 0]  \n",
    "    weights = weights.getA()  # convert mat to array  \n",
    "    y_min_x = float(-weights[0] - weights[1] * min_x) / weights[2]  \n",
    "    y_max_x = float(-weights[0] - weights[1] * max_x) / weights[2]  \n",
    "    plt.plot([min_x, max_x], [y_min_x, y_max_x], '-g')  \n",
    "    plt.xlabel('X1'); plt.ylabel('X2')  \n",
    "    plt.show()  \n",
    "\n",
    "## step 1: load data  \n",
    "print(\"step 1: load data...\")  \n",
    "train_x, train_y = loadData('hw1-train.dat')  \n",
    "test_x , test_y = loadData('hw1-test.dat')\n",
    "  \n",
    "## step 2: training...  \n",
    "print(\"step 2: training...\")  \n",
    "opts = {'alpha': 0.05, 'maxIter': 2333, 'optimizeType': 'stocGradDescent'}  \n",
    "optimalWeights = trainLogRegres(train_x, train_y, opts)\n",
    "  \n",
    "print(optimalWeights.transpose())\n",
    "## step 3: testing  \n",
    "print(\"step 3: testing...\")  \n",
    "accuracy = testLogRegres(optimalWeights, test_x, test_y)  \n",
    "  \n",
    "## step 4: show the result  \n",
    "print(\"step 4: show the result...\")    \n",
    "print('The classify accuracy is: %.3f%%' % (accuracy * 100))  \n",
    "\n",
    "# showLogRegres(optimalWeights, train_x, train_y) \n",
    "# showLogRegres(optimalWeights, test_x, test_y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2: training...\n",
      "Error of input is: [[ 0.55020596]]\n",
      "\n",
      "[[-0.67826324 -0.90828869  1.29891616 -1.54594599  0.09601133 -1.52143659\n",
      "  -0.0340893   1.83221197 -1.11267587  0.68557871  2.05633956  0.45317084\n",
      "  -1.38018909 -0.88556539  1.24783298  1.66839032  1.93862715 -1.86493214\n",
      "   2.02435254 -0.83407311 -1.45814607]]\n",
      "step 3: testing...\n",
      "Error of output is: [[ 0.57758489]]\n",
      "\n",
      "step 4: show the result...\n",
      "The classify accuracy is: 81.733%\n"
     ]
    }
   ],
   "source": [
    "## step 2: training...  \n",
    "print(\"step 2: training...\")  \n",
    "opts = {'alpha': 0.005, 'maxIter': 2333, 'optimizeType': 'stocGradDescent'}  \n",
    "optimalWeights = trainLogRegres(train_x, train_y, opts)\n",
    "  \n",
    "print(optimalWeights.transpose())\n",
    "## step 3: testing  \n",
    "print(\"step 3: testing...\")  \n",
    "accuracy = testLogRegres(optimalWeights, test_x, test_y)  \n",
    "  \n",
    "## step 4: show the result  \n",
    "print(\"step 4: show the result...\")    \n",
    "print('The classify accuracy is: %.3f%%' % (accuracy * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2: training...\n",
      "Error of input is: [[ 11.21713337]]\n",
      "\n",
      "[[-32.01856896 -28.6596104   35.16036555 -48.09169144  -0.42625936\n",
      "  -49.57613521  -4.48298079  46.76817399 -31.66092971  20.39356144\n",
      "   57.89219242   9.19010902 -39.36255989 -28.8717769   33.38720749\n",
      "   45.91434892  50.0175759  -58.33231406  57.47767261 -26.2554072\n",
      "  -51.14191945]]\n",
      "step 3: testing...\n",
      "Error of output is: [[ 12.21447953]]\n",
      "\n",
      "step 4: show the result...\n",
      "The classify accuracy is: 63.300%\n"
     ]
    }
   ],
   "source": [
    "## step 2: training...  \n",
    "print(\"step 2: training...\")  \n",
    "opts = {'alpha': 0.05, 'maxIter': 2333, 'optimizeType': 'gradDescent'}  \n",
    "optimalWeights = trainLogRegres(train_x, train_y, opts)\n",
    "  \n",
    "print(optimalWeights.transpose())\n",
    "## step 3: testing  \n",
    "print(\"step 3: testing...\")  \n",
    "accuracy = testLogRegres(optimalWeights, test_x, test_y)  \n",
    "  \n",
    "## step 4: show the result  \n",
    "print(\"step 4: show the result...\")    \n",
    "print('The classify accuracy is: %.3f%%' % (accuracy * 100)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2: training...\n",
      "Error of input is: [[ 1.36162082]]\n",
      "\n",
      "[[-3.1223357  -2.84517565  3.33529599 -4.59971463 -0.07943446 -4.59202993\n",
      "  -0.37412498  4.63379717 -3.29247014  1.81411094  5.6514972   1.04387252\n",
      "  -3.9047586  -2.85612157  3.25651612  4.46983198  5.16899679 -5.51047803\n",
      "   5.55677417 -2.63272552 -4.59776347]]\n",
      "step 3: testing...\n",
      "Error of output is: [[ 1.46014497]]\n",
      "\n",
      "step 4: show the result...\n",
      "The classify accuracy is: 64.800%\n"
     ]
    }
   ],
   "source": [
    "## step 2: training...  \n",
    "print(\"step 2: training...\")  \n",
    "opts = {'alpha': 0.005, 'maxIter': 2333, 'optimizeType': 'gradDescent'}  \n",
    "optimalWeights = trainLogRegres(train_x, train_y, opts)\n",
    "  \n",
    "print(optimalWeights.transpose())\n",
    "## step 3: testing  \n",
    "print(\"step 3: testing...\")  \n",
    "accuracy = testLogRegres(optimalWeights, test_x, test_y)  \n",
    "  \n",
    "## step 4: show the result  \n",
    "print(\"step 4: show the result...\")    \n",
    "print('The classify accuracy is: %.3f%%' % (accuracy * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Essay Questions\n",
    "\n",
    "_You may choose to do the essay questions here in the .ipynb notebook, but you are welcomed to use a word processor instead and write your solutions there instead (and convert it into .pdf format).  If you do that, please ensure to delete this section._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. [LFD Exercise 1.2] Suppose that we use a perceptron to detect spam messages. Let's say that each email messages represented by the frequency of occurrence of keywords, and the output is +1 if the message is considered spam.\n",
    "\n",
    "    1. Can you think of some keywords that will end up with a large positive weight into perceptron?\n",
    "\n",
    "    2. How about keywords that will get a negative weight?\n",
    "\n",
    "    3. What parameter in the perceptron directly affects how many borderline messages end up classified as spam?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Keywords that lead to a positive weight indicates that messages with the keyword are more likely to be spamming. Some words that are very casual or oral , or leading receiver to pay money are likely to be spamming. For examples, 'pay','credit card' or 'buy'.\n",
    "\n",
    "2. Keywords contribute a negative weight if they are not likely to be spamming. If words are very written or official, they are likely to be not spamming. Examples like 'purchase'.\n",
    "\n",
    "3. Parameters to control the strictness of the checking are like message length or message sending rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Consider a coin tossing experiment. You toss a coin 100 times, with the result of heads 70 times and tails 30 times. We denote the probability of heads of this coin as Θ. Now consider a coin toss.\n",
    "\n",
    "    1. Build a model using maximum lilkelihood estimation (MLE) to infer Θ.\n",
    "\n",
    "    2. Can we judge that this is an unfair coin? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We can probably use logistic regression to do the estimation of classification. If head faces up, note the result as 1,otherwise 0. \n",
    "    A sample model is to use sigmod function = 1 / (1 + e^(-f(x))) in which f(x) is a linear regression with regards to the parameters like Throwing angle , starting speed, or air speed. Suppose the measurements of the parameters are possible, we can conduct logistic regression to gain the weightage for each attribute. \n",
    "2. We cannot conclude that this is an unfair coin, since we need to analyze the obtained model. The above mentioned attributes are likely to affect the final result. The higher chance of head tossing may be due to the person's throwing sense. We will nedd to analyze the obtained weightage and compare it with a normal coin to see whether this one is unfair or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. In the programming logistic regression, part (c), we did away with the stochastic idea of SGD and substituted a round-robin version, which deterministically uses the next point in turn to perform the gradient descent. Describe whether you think this is a good robust idea or not for datasets in general."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A round robin method may not be robust since it may be stuck in the local extreme value. If the function has both minimum and global minimum, a round robin method is likely to stop at a local minimum, which is not really optimal. There must be some methods to escape from local extreme value. SGD method can avoid local minimum by randomly jump through the local extrme value. Besides, since a deterministic method is used, the obtained result must be same every time to run it. This is not suitable to experiment for multiple different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement of Individual Work\n",
    "\n",
    "Please initial (between the square brackets) one of the following statements.\n",
    "\n",
    "[I] I,A0153633J, certify that I have followed the CS 3244 Machine Learning class guidelines for homework assignments.  In particular, I expressly vow that I have followed the Facebook rule in discussing with others in doing the assignment and did not take notes (digital or printed) from the discussions.  \n",
    "\n",
    "[ ] I, <*substitute your matric number here*>, did not follow the class rules regarding the homework assignment, because of the following reason:\n",
    "\n",
    "<*Please fill in*>\n",
    "\n",
    "I suggest that I should be graded as follows:\n",
    "\n",
    "A\n",
    "\n",
    "### References\n",
    "\n",
    "I have refered to the following list of people and websites in preparing my homework submission:\n",
    "\n",
    "http://docs.scipy.org/doc/numpy/reference/index.html\n",
    "http://matplotlib.org/contents.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
